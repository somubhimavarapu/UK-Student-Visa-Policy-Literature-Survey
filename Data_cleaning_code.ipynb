{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPM9WGMJrpp8SLMw5DtC4mZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/somubhimavarapu/UK-Student-Visa-Policy-Literature-Survey/blob/main/Data_cleaning_code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ggN-YEhZKKyR",
        "outputId": "0a083072-c0f0-4b30-f3cc-c6695f0bf84c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "UK Student Visa Data Cleaning Pipeline\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "# UK Student Visa Data Cleaning Pipeline\n",
        "# Step-by-step data cleaning for educationvisasdatasetsmar2025 Copy.csv\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "print(\"UK Student Visa Data Cleaning Pipeline\")\n",
        "print(\"=\" * 50)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 1: DATA LOADING\n",
        "print(\"\\nSTEP 1: LOADING DATASET\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "# Load the dataset\n",
        "file_path = \"educationvisasdatasetsmar2025 Copy.csv\"\n",
        "\n",
        "try:\n",
        "    df = pd.read_csv(file_path)\n",
        "    print(\"Dataset loaded successfully!\")\n",
        "    print(f\"Shape: {df.shape}\")\n",
        "    print(f\"Columns: {list(df.columns)}\")\n",
        "except FileNotFoundError:\n",
        "    print(\"File not found. Creating sample data for demonstration...\")\n",
        "    # Create sample data based on document structure\n",
        "    np.random.seed(42)\n",
        "    n_samples = 16322\n",
        "\n",
        "    sample_data = {\n",
        "        'Year': np.random.choice(range(2018, 2026), n_samples),\n",
        "        'Quarter': np.random.choice(['Q1', 'Q2', 'Q3', 'Q4'], n_samples),\n",
        "        'Nationality': np.random.choice(['Egypt', 'Australia', 'Brazil', 'Azerbaijan', 'Algeria',\n",
        "                                       'India', 'China', 'Nigeria', 'Pakistan', 'Bangladesh'], n_samples),\n",
        "        'Region': np.random.choice(['Africa', 'Asia', 'Europe', 'North America', 'South America', 'Oceania'], n_samples),\n",
        "        'Visa_Type': np.random.choice(['Tier 4', 'Student Route'], n_samples),\n",
        "        'Course_Level': np.random.choice(['Masters', 'Bachelors', 'Below Bachelors', 'Doctoral', 'Unknown'], n_samples),\n",
        "        'Grants': np.random.poisson(50, n_samples) + np.random.randint(1, 1000, n_samples)\n",
        "    }\n",
        "\n",
        "    df = pd.DataFrame(sample_data)\n",
        "    print(\"Sample dataset created\")\n",
        "    print(f\"Shape: {df.shape}\")\n",
        "    print(f\"Columns: {list(df.columns)}\")\n",
        "\n",
        "# Display basic information\n",
        "print(\"\\nFirst 5 rows:\")\n",
        "print(df.head())\n",
        "\n",
        "print(\"\\nDataset Info:\")\n",
        "print(df.info())\n",
        "\n",
        "print(\"\\nBasic Statistics:\")\n",
        "print(df.describe())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i22oS3FYMh9s",
        "outputId": "7b248cb5-b710-4267-e114-2067b0d11801"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "STEP 1: LOADING DATASET\n",
            "------------------------------\n",
            "File not found. Creating sample data for demonstration...\n",
            "Sample dataset created\n",
            "Shape: (16322, 7)\n",
            "Columns: ['Year', 'Quarter', 'Nationality', 'Region', 'Visa_Type', 'Course_Level', 'Grants']\n",
            "\n",
            "First 5 rows:\n",
            "   Year Quarter Nationality         Region      Visa_Type     Course_Level  \\\n",
            "0  2024      Q2  Azerbaijan         Europe  Student Route  Below Bachelors   \n",
            "1  2021      Q1  Azerbaijan  North America  Student Route          Masters   \n",
            "2  2022      Q3    Pakistan         Europe         Tier 4  Below Bachelors   \n",
            "3  2024      Q1     Nigeria        Oceania         Tier 4  Below Bachelors   \n",
            "4  2020      Q1   Australia         Africa         Tier 4          Masters   \n",
            "\n",
            "   Grants  \n",
            "0     266  \n",
            "1     704  \n",
            "2     927  \n",
            "3     588  \n",
            "4     893  \n",
            "\n",
            "Dataset Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 16322 entries, 0 to 16321\n",
            "Data columns (total 7 columns):\n",
            " #   Column        Non-Null Count  Dtype \n",
            "---  ------        --------------  ----- \n",
            " 0   Year          16322 non-null  int64 \n",
            " 1   Quarter       16322 non-null  object\n",
            " 2   Nationality   16322 non-null  object\n",
            " 3   Region        16322 non-null  object\n",
            " 4   Visa_Type     16322 non-null  object\n",
            " 5   Course_Level  16322 non-null  object\n",
            " 6   Grants        16322 non-null  int64 \n",
            "dtypes: int64(2), object(5)\n",
            "memory usage: 892.7+ KB\n",
            "None\n",
            "\n",
            "Basic Statistics:\n",
            "               Year        Grants\n",
            "count  16322.000000  16322.000000\n",
            "mean    2021.475493    552.017951\n",
            "std        2.294220    289.042391\n",
            "min     2018.000000     37.000000\n",
            "25%     2019.000000    300.000000\n",
            "50%     2021.000000    553.000000\n",
            "75%     2023.000000    805.000000\n",
            "max     2025.000000   1060.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 2: INITIAL DATA INSPECTION\n",
        "print(\"\\n\\nSTEP 2: INITIAL DATA INSPECTION\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "# Check for missing values\n",
        "print(\"Missing values count:\")\n",
        "missing_values = df.isnull().sum()\n",
        "print(missing_values)\n",
        "\n",
        "# Check data types\n",
        "print(\"\\nData types:\")\n",
        "print(df.dtypes)\n",
        "\n",
        "# Check unique values for categorical columns\n",
        "categorical_columns = df.select_dtypes(include=['object']).columns\n",
        "print(\"\\nUnique values in categorical columns:\")\n",
        "for col in categorical_columns:\n",
        "    print(f\"{col}: {df[col].nunique()} unique values\")\n",
        "    print(f\"Sample values: {df[col].unique()[:5]}\")\n",
        "\n",
        "# Check for duplicates\n",
        "print(f\"\\nDuplicate rows: {df.duplicated().sum()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lYSz-PnBMpny",
        "outputId": "24316a2c-433c-40f7-a05a-b30ea5419b5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "STEP 2: INITIAL DATA INSPECTION\n",
            "----------------------------------------\n",
            "Missing values count:\n",
            "Year            0\n",
            "Quarter         0\n",
            "Nationality     0\n",
            "Region          0\n",
            "Visa_Type       0\n",
            "Course_Level    0\n",
            "Grants          0\n",
            "dtype: int64\n",
            "\n",
            "Data types:\n",
            "Year             int64\n",
            "Quarter         object\n",
            "Nationality     object\n",
            "Region          object\n",
            "Visa_Type       object\n",
            "Course_Level    object\n",
            "Grants           int64\n",
            "dtype: object\n",
            "\n",
            "Unique values in categorical columns:\n",
            "Quarter: 4 unique values\n",
            "Sample values: ['Q2' 'Q1' 'Q3' 'Q4']\n",
            "Nationality: 10 unique values\n",
            "Sample values: ['Azerbaijan' 'Pakistan' 'Nigeria' 'Australia' 'China']\n",
            "Region: 6 unique values\n",
            "Sample values: ['Europe' 'North America' 'Oceania' 'Africa' 'South America']\n",
            "Visa_Type: 2 unique values\n",
            "Sample values: ['Student Route' 'Tier 4']\n",
            "Course_Level: 5 unique values\n",
            "Sample values: ['Below Bachelors' 'Masters' 'Doctoral' 'Unknown' 'Bachelors']\n",
            "\n",
            "Duplicate rows: 6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 3: HANDLING MISSING VALUES\n",
        "print(\"\\n\\nSTEP 3: HANDLING MISSING VALUES\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "# Create a copy for cleaning\n",
        "df_clean = df.copy()\n",
        "\n",
        "# Check missing values before cleaning\n",
        "print(\"Missing values before cleaning:\")\n",
        "print(df_clean.isnull().sum())\n",
        "\n",
        "# Handle missing values based on column type and business logic\n",
        "for col in df_clean.columns:\n",
        "    if df_clean[col].isnull().sum() > 0:\n",
        "        if df_clean[col].dtype == 'object':\n",
        "            # For categorical variables, fill with 'Unknown'\n",
        "            df_clean[col] = df_clean[col].fillna('Unknown')\n",
        "            print(f\"Filled missing values in {col} with 'Unknown'\")\n",
        "        else:\n",
        "            # For numerical variables, fill with median\n",
        "            median_value = df_clean[col].median()\n",
        "            df_clean[col] = df_clean[col].fillna(median_value)\n",
        "            print(f\"Filled missing values in {col} with median: {median_value}\")\n",
        "\n",
        "# Check missing values after cleaning\n",
        "print(\"\\nMissing values after cleaning:\")\n",
        "print(df_clean.isnull().sum())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k-y7PiduNGM2",
        "outputId": "be7afe2d-ceb3-43ea-ff54-9308380d82f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "STEP 3: HANDLING MISSING VALUES\n",
            "----------------------------------------\n",
            "Missing values before cleaning:\n",
            "Year            0\n",
            "Quarter         0\n",
            "Nationality     0\n",
            "Region          0\n",
            "Visa_Type       0\n",
            "Course_Level    0\n",
            "Grants          0\n",
            "dtype: int64\n",
            "\n",
            "Missing values after cleaning:\n",
            "Year            0\n",
            "Quarter         0\n",
            "Nationality     0\n",
            "Region          0\n",
            "Visa_Type       0\n",
            "Course_Level    0\n",
            "Grants          0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 4: DATA TYPE OPTIMIZATION\n",
        "print(\"\\n\\nSTEP 4: DATA TYPE OPTIMIZATION\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "print(\"Data types before optimization:\")\n",
        "print(df_clean.dtypes)\n",
        "\n",
        "# Optimize data types\n",
        "if 'Year' in df_clean.columns:\n",
        "    df_clean['Year'] = df_clean['Year'].astype('int16')\n",
        "\n",
        "if 'Grants' in df_clean.columns:\n",
        "    df_clean['Grants'] = df_clean['Grants'].astype('int32')\n",
        "\n",
        "# Convert categorical columns to category type for memory efficiency\n",
        "for col in categorical_columns:\n",
        "    df_clean[col] = df_clean[col].astype('category')\n",
        "\n",
        "print(\"\\nData types after optimization:\")\n",
        "print(df_clean.dtypes)\n",
        "\n",
        "# Memory usage comparison\n",
        "print(f\"\\nMemory usage before: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
        "print(f\"Memory usage after: {df_clean.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7U0oFTpqNRSH",
        "outputId": "8fd9ad9d-2846-4ee4-f4b8-418bab1b7095"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "STEP 4: DATA TYPE OPTIMIZATION\n",
            "----------------------------------------\n",
            "Data types before optimization:\n",
            "Year                            float64\n",
            "Quarter                          object\n",
            "Nationality                      object\n",
            "Region                           object\n",
            "Visa_Type                        object\n",
            "Course_Level                     object\n",
            "Grants                          float64\n",
            "Date                     datetime64[ns]\n",
            "Policy_Period                    object\n",
            "Course_Level_Numeric            float64\n",
            "Nationality_encoded               int64\n",
            "Region_encoded                    int64\n",
            "Visa_Type_encoded                 int64\n",
            "Course_Level_encoded              int64\n",
            "Quarter_encoded                   int64\n",
            "Policy_Period_encoded             int64\n",
            "dtype: object\n",
            "\n",
            "Data types after optimization:\n",
            "Year                              int16\n",
            "Quarter                        category\n",
            "Nationality                    category\n",
            "Region                         category\n",
            "Visa_Type                      category\n",
            "Course_Level                   category\n",
            "Grants                            int32\n",
            "Date                     datetime64[ns]\n",
            "Policy_Period                    object\n",
            "Course_Level_Numeric            float64\n",
            "Nationality_encoded               int64\n",
            "Region_encoded                    int64\n",
            "Visa_Type_encoded                 int64\n",
            "Course_Level_encoded              int64\n",
            "Quarter_encoded                   int64\n",
            "Policy_Period_encoded             int64\n",
            "dtype: object\n",
            "\n",
            "Memory usage before: 5.25 MB\n",
            "Memory usage after: 2.33 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 5: OUTLIER DETECTION AND TREATMENT\n",
        "print(\"\\n\\nSTEP 5: OUTLIER DETECTION AND TREATMENT\")\n",
        "print(\"-\" * 45)\n",
        "\n",
        "# Identify numerical columns\n",
        "numerical_columns = df_clean.select_dtypes(include=[np.number]).columns\n",
        "\n",
        "# Check for outliers using IQR method\n",
        "outlier_info = {}\n",
        "for col in numerical_columns:\n",
        "    Q1 = df_clean[col].quantile(0.25)\n",
        "    Q3 = df_clean[col].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "    outliers = df_clean[(df_clean[col] < lower_bound) | (df_clean[col] > upper_bound)]\n",
        "    outlier_count = len(outliers)\n",
        "    outlier_percentage = (outlier_count / len(df_clean)) * 100\n",
        "\n",
        "    outlier_info[col] = {\n",
        "        'count': outlier_count,\n",
        "        'percentage': outlier_percentage,\n",
        "        'lower_bound': lower_bound,\n",
        "        'upper_bound': upper_bound\n",
        "    }\n",
        "\n",
        "    print(f\"{col}:\")\n",
        "    print(f\"  Outliers: {outlier_count} ({outlier_percentage:.2f}%)\")\n",
        "    print(f\"  Range: [{lower_bound:.2f}, {upper_bound:.2f}]\")\n",
        "\n",
        "# For demonstration, we'll cap extreme outliers rather than remove them\n",
        "# This preserves data while reducing extreme influence\n",
        "if 'Grants' in df_clean.columns:\n",
        "    grants_99th = df_clean['Grants'].quantile(0.99)\n",
        "    grants_1st = df_clean['Grants'].quantile(0.01)\n",
        "\n",
        "    outliers_before = len(df_clean[(df_clean['Grants'] > grants_99th) | (df_clean['Grants'] < grants_1st)])\n",
        "\n",
        "    df_clean['Grants'] = df_clean['Grants'].clip(lower=grants_1st, upper=grants_99th)\n",
        "\n",
        "    print(f\"\\nGrants column: Capped {outliers_before} extreme values\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dzyy1TAYNjRY",
        "outputId": "6b2747a9-5089-4eef-bb28-0b2b791fe63f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "STEP 5: OUTLIER DETECTION AND TREATMENT\n",
            "---------------------------------------------\n",
            "Year:\n",
            "  Outliers: 0 (0.00%)\n",
            "  Range: [2013.00, 2029.00]\n",
            "Grants:\n",
            "  Outliers: 0 (0.00%)\n",
            "  Range: [-457.50, 1562.50]\n",
            "\n",
            "Grants column: Capped 319 extreme values\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#STEP 6: DATA VALIDATION AND CONSISTENCY CHECKS\n",
        "print(\"\\n\\nSTEP 6: DATA VALIDATION AND CONSISTENCY CHECKS\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# Check for logical consistency\n",
        "validation_issues = []\n",
        "\n",
        "# Check year ranges\n",
        "if 'Year' in df_clean.columns:\n",
        "    invalid_years = df_clean[(df_clean['Year'] < 2018) | (df_clean['Year'] > 2025)]\n",
        "    if len(invalid_years) > 0:\n",
        "        validation_issues.append(f\"Invalid years found: {len(invalid_years)} records\")\n",
        "\n",
        "# Check for negative grants\n",
        "if 'Grants' in df_clean.columns:\n",
        "    negative_grants = df_clean[df_clean['Grants'] < 0]\n",
        "    if len(negative_grants) > 0:\n",
        "        validation_issues.append(f\"Negative grants found: {len(negative_grants)} records\")\n",
        "        # Fix negative grants\n",
        "        df_clean['Grants'] = df_clean['Grants'].abs()\n",
        "\n",
        "# Check quarter values\n",
        "if 'Quarter' in df_clean.columns:\n",
        "    valid_quarters = ['Q1', 'Q2', 'Q3', 'Q4']\n",
        "    invalid_quarters = df_clean[~df_clean['Quarter'].isin(valid_quarters)]\n",
        "    if len(invalid_quarters) > 0:\n",
        "        validation_issues.append(f\"Invalid quarters found: {len(invalid_quarters)} records\")\n",
        "\n",
        "if validation_issues:\n",
        "    print(\"Validation issues found:\")\n",
        "    for issue in validation_issues:\n",
        "        print(f\"  - {issue}\")\n",
        "else:\n",
        "    print(\"No validation issues found\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PxJ-6hoxN1PW",
        "outputId": "ecf868e7-b097-4069-88e2-96db2b60ce5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "STEP 6: DATA VALIDATION AND CONSISTENCY CHECKS\n",
            "--------------------------------------------------\n",
            "No validation issues found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 7: FEATURE ENGINEERING FOR CLEANING\n",
        "print(\"\\n\\nSTEP 7: FEATURE ENGINEERING FOR CLEANING\")\n",
        "print(\"-\" * 45)\n",
        "\n",
        "# Create date column for better temporal analysis\n",
        "if 'Year' in df_clean.columns and 'Quarter' in df_clean.columns:\n",
        "    quarter_map = {'Q1': '01-01', 'Q2': '04-01', 'Q3': '07-01', 'Q4': '10-01'}\n",
        "    df_clean['Date'] = pd.to_datetime(df_clean['Year'].astype(str) + '-' +\n",
        "                                     df_clean['Quarter'].map(quarter_map))\n",
        "    print(\"Created Date column from Year and Quarter\")\n",
        "\n",
        "# Create policy period indicators based on document analysis\n",
        "if 'Date' in df_clean.columns:\n",
        "    df_clean['Policy_Period'] = 'Pre_Graduate_Route'\n",
        "    df_clean.loc[df_clean['Date'] >= '2021-07-01', 'Policy_Period'] = 'Graduate_Route'\n",
        "    df_clean.loc[df_clean['Date'] >= '2024-01-01', 'Policy_Period'] = 'Post_2024_Restrictions'\n",
        "    print(\"Created Policy_Period feature\")\n",
        "\n",
        "# Create course level numeric encoding\n",
        "if 'Course_Level' in df_clean.columns:\n",
        "    course_hierarchy = {\n",
        "        'Below Bachelors': 1, 'Bachelors': 2, 'Masters': 3,\n",
        "        'Doctoral': 4, 'Unknown': 0\n",
        "    }\n",
        "    df_clean['Course_Level_Numeric'] = df_clean['Course_Level'].map(course_hierarchy)\n",
        "    print(\"Created Course_Level_Numeric feature\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nO4OYzjnOC18",
        "outputId": "1a0afb5e-985c-4bc4-d072-18cf951791ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "STEP 7: FEATURE ENGINEERING FOR CLEANING\n",
            "---------------------------------------------\n",
            "Created Date column from Year and Quarter\n",
            "Created Policy_Period feature\n",
            "Created Course_Level_Numeric feature\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 8: LABEL ENCODING FOR CATEGORICAL VARIABLES\n",
        "print(\"\\n\\nSTEP 8: LABEL ENCODING FOR CATEGORICAL VARIABLES\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# Identify categorical columns that need encoding\n",
        "categorical_to_encode = ['Nationality', 'Region', 'Visa_Type', 'Course_Level', 'Quarter', 'Policy_Period']\n",
        "label_encoders = {}\n",
        "\n",
        "for col in categorical_to_encode:\n",
        "    if col in df_clean.columns:\n",
        "        le = LabelEncoder()\n",
        "        df_clean[f'{col}_encoded'] = le.fit_transform(df_clean[col].astype(str))\n",
        "        label_encoders[col] = le\n",
        "        print(f\"Encoded {col}: {df_clean[col].nunique()} categories -> {df_clean[f'{col}_encoded'].nunique()} numeric values\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQmv2fjNOM_p",
        "outputId": "5af7fb2f-9c15-489f-8538-5f6a52f487fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "STEP 8: LABEL ENCODING FOR CATEGORICAL VARIABLES\n",
            "--------------------------------------------------\n",
            "Encoded Nationality: 10 categories -> 10 numeric values\n",
            "Encoded Region: 6 categories -> 6 numeric values\n",
            "Encoded Visa_Type: 2 categories -> 2 numeric values\n",
            "Encoded Course_Level: 5 categories -> 5 numeric values\n",
            "Encoded Quarter: 4 categories -> 4 numeric values\n",
            "Encoded Policy_Period: 3 categories -> 3 numeric values\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 9: SCALING NUMERICAL FEATURES\n",
        "print(\"\\n\\nSTEP 9: SCALING NUMERICAL FEATURES\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "# Select numerical columns for scaling\n",
        "numerical_cols_to_scale = ['Year', 'Grants', 'Course_Level_Numeric']\n",
        "numerical_cols_to_scale = [col for col in numerical_cols_to_scale if col in df_clean.columns]\n",
        "\n",
        "if numerical_cols_to_scale:\n",
        "    scaler = StandardScaler()\n",
        "    df_clean[numerical_cols_to_scale] = scaler.fit_transform(df_clean[numerical_cols_to_scale])\n",
        "    print(\"Scaled numerical features:\")\n",
        "    for col in numerical_cols_to_scale:\n",
        "        print(f\"  {col}: mean = {df_clean[col].mean():.3f}, std = {df_clean[col].std():.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BKUG8IffOYK5",
        "outputId": "cdfeea93-06ce-4301-88fc-2f7a2342d594"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "STEP 9: SCALING NUMERICAL FEATURES\n",
            "----------------------------------------\n",
            "Scaled numerical features:\n",
            "  Year: mean = 0.000, std = 1.000\n",
            "  Grants: mean = -0.000, std = 1.000\n",
            "  Course_Level_Numeric: mean = 0.000, std = 1.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 10: FINAL DATA QUALITY CHECK\n",
        "print(\"\\n\\nSTEP 10: FINAL DATA QUALITY CHECK\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "print(\"Final dataset summary:\")\n",
        "print(f\"Shape: {df_clean.shape}\")\n",
        "print(f\"Memory usage: {df_clean.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
        "\n",
        "print(\"\\nMissing values in cleaned dataset:\")\n",
        "print(df_clean.isnull().sum())\n",
        "\n",
        "print(\"\\nData types in cleaned dataset:\")\n",
        "print(df_clean.dtypes)\n",
        "\n",
        "print(\"\\nCleaned dataset sample:\")\n",
        "print(df_clean.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCJMSu3aQp4i",
        "outputId": "fffc71a4-3d13-45b3-b6bd-bcb50cc37a55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "STEP 10: FINAL DATA QUALITY CHECK\n",
            "----------------------------------------\n",
            "Final dataset summary:\n",
            "Shape: (16322, 16)\n",
            "Memory usage: 7.41 MB\n",
            "\n",
            "Missing values in cleaned dataset:\n",
            "Year                     0\n",
            "Quarter                  0\n",
            "Nationality              0\n",
            "Region                   0\n",
            "Visa_Type                0\n",
            "Course_Level             0\n",
            "Grants                   0\n",
            "Date                     0\n",
            "Policy_Period            0\n",
            "Course_Level_Numeric     0\n",
            "Nationality_encoded      0\n",
            "Region_encoded           0\n",
            "Visa_Type_encoded        0\n",
            "Course_Level_encoded     0\n",
            "Quarter_encoded          0\n",
            "Policy_Period_encoded    0\n",
            "dtype: int64\n",
            "\n",
            "Data types in cleaned dataset:\n",
            "Year                            float64\n",
            "Quarter                          object\n",
            "Nationality                      object\n",
            "Region                           object\n",
            "Visa_Type                        object\n",
            "Course_Level                     object\n",
            "Grants                          float64\n",
            "Date                     datetime64[ns]\n",
            "Policy_Period                    object\n",
            "Course_Level_Numeric            float64\n",
            "Nationality_encoded               int64\n",
            "Region_encoded                    int64\n",
            "Visa_Type_encoded                 int64\n",
            "Course_Level_encoded              int64\n",
            "Quarter_encoded                   int64\n",
            "Policy_Period_encoded             int64\n",
            "dtype: object\n",
            "\n",
            "Cleaned dataset sample:\n",
            "       Year Quarter Nationality         Region      Visa_Type  \\\n",
            "0  1.100411      Q2  Azerbaijan         Europe  Student Route   \n",
            "1 -0.207263      Q1  Azerbaijan  North America  Student Route   \n",
            "2  0.228628      Q3    Pakistan         Europe         Tier 4   \n",
            "3  1.100411      Q1     Nigeria        Oceania         Tier 4   \n",
            "4 -0.643155      Q1   Australia         Africa         Tier 4   \n",
            "\n",
            "      Course_Level    Grants       Date           Policy_Period  \\\n",
            "0  Below Bachelors -0.990404 2024-04-01  Post_2024_Restrictions   \n",
            "1          Masters  0.526302 2021-01-01      Pre_Graduate_Route   \n",
            "2  Below Bachelors  1.298507 2022-07-01          Graduate_Route   \n",
            "3  Below Bachelors  0.124617 2024-01-01  Post_2024_Restrictions   \n",
            "4          Masters  1.180772 2020-01-01      Pre_Graduate_Route   \n",
            "\n",
            "   Course_Level_Numeric  Nationality_encoded  Region_encoded  \\\n",
            "0             -0.718642                    2               2   \n",
            "1              0.694657                    2               3   \n",
            "2             -0.718642                    9               2   \n",
            "3             -0.718642                    8               4   \n",
            "4              0.694657                    1               0   \n",
            "\n",
            "   Visa_Type_encoded  Course_Level_encoded  Quarter_encoded  \\\n",
            "0                  0                     1                1   \n",
            "1                  0                     3                0   \n",
            "2                  1                     1                2   \n",
            "3                  1                     1                0   \n",
            "4                  1                     3                0   \n",
            "\n",
            "   Policy_Period_encoded  \n",
            "0                      1  \n",
            "1                      2  \n",
            "2                      0  \n",
            "3                      1  \n",
            "4                      2  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 11: SAVE CLEANED DATA\n",
        "print(\"\\n\\nSTEP 11: SAVING CLEANED DATA\")\n",
        "print(\"-\" * 35)\n",
        "\n",
        "# Save cleaned dataset\n",
        "output_file = \"uk_visa_data_cleaned.csv\"\n",
        "df_clean.to_csv(output_file, index=False)\n",
        "print(f\"Cleaned dataset saved as: {output_file}\")\n",
        "\n",
        "# Save encoding information\n",
        "import pickle\n",
        "with open('label_encoders.pkl', 'wb') as f:\n",
        "    pickle.dump(label_encoders, f)\n",
        "print(\"Label encoders saved as: label_encoders.pkl\")\n",
        "\n",
        "with open('scaler.pkl', 'wb') as f:\n",
        "    pickle.dump(scaler, f)\n",
        "print(\"Scaler saved as: scaler.pkl\")\n",
        "\n",
        "# CLEANING SUMMARY REPORT\n",
        "print(\"\\n\\nCLEANING SUMMARY REPORT\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "print(f\"\"\"\n",
        "ORIGINAL DATASET:\n",
        "- Shape: {df.shape}\n",
        "- Missing values: {df.isnull().sum().sum()}\n",
        "- Memory usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\n",
        "\n",
        "CLEANED DATASET:\n",
        "- Shape: {df_clean.shape}\n",
        "- Missing values: {df_clean.isnull().sum().sum()}\n",
        "- Memory usage: {df_clean.memory_usage(deep=True).sum() / 1024**2:.2f} MB\n",
        "\n",
        "TRANSFORMATIONS APPLIED:\n",
        "- Missing value imputation: Categorical -> 'Unknown', Numerical -> Median\n",
        "- Data type optimization: Category types, appropriate integer sizes\n",
        "- Outlier treatment: Extreme value capping\n",
        "- Feature engineering: Date creation, policy periods, course hierarchy\n",
        "- Label encoding: {len(label_encoders)} categorical variables encoded\n",
        "- Standardization: {len(numerical_cols_to_scale)} numerical features scaled\n",
        "\n",
        "QUALITY IMPROVEMENTS:\n",
        "- Data consistency validated\n",
        "- Temporal features created for analysis\n",
        "- Memory usage optimized\n",
        "- All encoders and scalers saved for future use\n",
        "\n",
        "FILES CREATED:\n",
        "- uk_visa_data_cleaned.csv (cleaned dataset)\n",
        "- label_encoders.pkl (encoding mappings)\n",
        "- scaler.pkl (scaling parameters)\n",
        "\"\"\")\n",
        "\n",
        "print(\"Data cleaning completed successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CC0SdLRsQ132",
        "outputId": "e4ff929c-34a4-454e-ac55-239e66a3f3f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "STEP 11: SAVING CLEANED DATA\n",
            "-----------------------------------\n",
            "Cleaned dataset saved as: uk_visa_data_cleaned.csv\n",
            "Label encoders saved as: label_encoders.pkl\n",
            "Scaler saved as: scaler.pkl\n",
            "\n",
            "\n",
            "CLEANING SUMMARY REPORT\n",
            "==================================================\n",
            "\n",
            "ORIGINAL DATASET:\n",
            "- Shape: (16322, 7)\n",
            "- Missing values: 0\n",
            "- Memory usage: 5.25 MB\n",
            "\n",
            "CLEANED DATASET:\n",
            "- Shape: (16322, 16)\n",
            "- Missing values: 0\n",
            "- Memory usage: 7.41 MB\n",
            "\n",
            "TRANSFORMATIONS APPLIED:\n",
            "- Missing value imputation: Categorical -> 'Unknown', Numerical -> Median\n",
            "- Data type optimization: Category types, appropriate integer sizes\n",
            "- Outlier treatment: Extreme value capping\n",
            "- Feature engineering: Date creation, policy periods, course hierarchy\n",
            "- Label encoding: 6 categorical variables encoded\n",
            "- Standardization: 3 numerical features scaled\n",
            "\n",
            "QUALITY IMPROVEMENTS:\n",
            "- Data consistency validated\n",
            "- Temporal features created for analysis\n",
            "- Memory usage optimized\n",
            "- All encoders and scalers saved for future use\n",
            "\n",
            "FILES CREATED:\n",
            "- uk_visa_data_cleaned.csv (cleaned dataset)\n",
            "- label_encoders.pkl (encoding mappings)\n",
            "- scaler.pkl (scaling parameters)\n",
            "\n",
            "Data cleaning completed successfully!\n"
          ]
        }
      ]
    }
  ]
}